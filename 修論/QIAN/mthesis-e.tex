\documentclass[a4paper,11pt,oneside,openany]{book}

\usepackage[left=30mm,right=30mm,top=25mm,bottom=25mm]{geometry}
\usepackage{cscover}
\usepackage[dvipdfmx]{graphicx}
\usepackage[nobreak]{cite}
\usepackage[a4paper,dvipdfmx,pdfdisplaydoctitle=true,%
    bookmarks=true,bookmarksnumbered=true,bookmarkstype=toc,bookmarksopen=true,%
    pdftitle={A Study on Thesis Formats},%
    pdfauthor={Taro Tokodai}%
    ]{hyperref}

%\usepackage{titling} % Customizing the title section
\usepackage[dvipdfmx]{color}
\usepackage{tikz}
\usetikzlibrary{shapes.geometric,arrows,positioning}
\usepackage{hyperref} % For hyperlinks in the PDF
\usepackage{color}
\usepackage{caption,subcaption}
\usepackage{amsmath}
\usepackage{multirow}
\usepackage{mathtools}
\usepackage{algorithm,algorithmic}
\usepackage{amssymb}

%--------------------------------------------
% code style
%---------------------------------------------
%\usepackage{lstlinebgrd}
\usepackage{xcolor}
\usepackage{listings}
\renewcommand\lstlistingname{Figure}
\renewcommand\lstlistlistingname{Figures}

% Color
\definecolor{mGreen}{rgb}{0,0.6,0}
\definecolor{mGray}{rgb}{0.5,0.5,0.5}
\definecolor{mPurple}{rgb}{0.58,0,0.82}
\definecolor{backgroundColour}{rgb}{0.95,0.95,0.92}
\definecolor{Blue}{HTML}{2d5ae0}
\definecolor{Orange}{HTML}{e33900}
\definecolor{Green}{HTML}{009e73}
\definecolor{Purple}{HTML}{9400d3}

\lstdefinestyle{CStyle}{
    backgroundcolor=\color{backgroundColour},   
    frame=single,
    framexleftmargin=1em,
    %xleftmargin=0.5em,
    commentstyle=\color{mGreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{mGray},
    stringstyle=\color{mPurple},
    basicstyle=\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2,
    language=C
}
\lstset{
  style=CStyle,
  moredelim=[is][\color{Blue}\bfseries]{<\#blue\#}{\#>},
  moredelim=[is][\color{Orange}\bfseries]{<\#orange\#}{\#>},
  moredelim=[is][\color{Green}\bfseries]{<\#green\#}{\#>},
  moredelim=[is][\color{Purple}\bfseries]{<\#purple\#}{\#>},
}
\renewcommand{\bibname}{References}
\pagestyle{plain}

\thesistype{Master's Thesis}
%\thesistype{Doctoral Dissertation}
\title{Automated Memory Error Repair\\Based on Hybrid Program Analysis}
\author{ZECHANG QIAN}
\studentid{20M31355}
\affiliation{%
  Graduate Major in Computer Science\\
  %Graduate Major in Artificial Intelligence\\
  School of Computing\\
  Tokyo Institute of Technology}
\date{January, 2022}

\supervisorname{Supervisor:}
\supervisor{Katsuhiko Gondow}
%\dsupervisorname{Deputy Supervisor:}
%\dsupervisor{Jiro Kogaku}

\begin{document}

\frontmatter
\maketitle

\chapter{Abstract}
Automated program repair is a technology that aims to fix program errors and vulnerabilities automatically. In the field of memory error repair, with the development of bug detection tools, we can easily detect memory errors in programs. However, fixing those errors is time-consuming and error-prone. The program's heap-related behaviors, such as heap object, error source and sink, play a critical role in memory error repair, so how to detect the errors and collect the relevant information are the main tasks. The existing techniques are mainly based on static analysis, where the static analyzer is used to detect program memory errors and then repair tools collect the essential information via static analysis. But static analyzer may give wrong alarms which will affect the performance of the repair tools, and heap-related behavior analyzing often requires high overhead. 

We present \textbf{HAMER}, a hybrid automated memory error repair tool that aims to address those 
shortcomings by using hybrid analysis. HAMER first uses fuzzer to check the alarms given by the static 
analyzer and extracts the real errors from those alarms. Then it tries to fix those errors by using 
hybrid analysis. HAMER is an automated memory error repair technique based on fuzzing results. HAMER does not waste time resolving alarms that are incorrect because the errors reported by fuzzer are real errors, and HAMER also utilizes fuzzer to verify the generated patches to ensure they are correct. For the necessary information for synthesizing patches, HAMER uses existing lightweight static analysis techniques to collect it. Our preliminary experiment suggests that HAMER can fix the complicated memory errors effectively, which the existing static memory error repair technique can not repair.


\tableofcontents
\listoffigures
\listoftables

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\mainmatter
\chapter{Introduction}
Memory errors, such as memory leaks, can have catastrophic effects,  thus detecting and fixing them has always been a critical task for developers. Memory error detection performance is improving with the development of memory error detection technologies, however resolving these problems takes a lot of time and work for developers, and erroneous patches might lead to more significant effects.

Existing memory leak detection techniques can report the locations where the memory error occurs. But fixing these errors needs not only the error heap objects but also the suitable fix location and the heap-related behaviors.  Furthermore, the allocation location and the utilized location are usually passed between functions and it is often difficult for the developer to find the suitable points to deallocate the memory. If developers insert the wrong patch or insert the patch at the wrong point, it may cause more significant errors.

Existing memory error repair techniques~\cite{SAVER,Memfix} are mainly based on static analysis. This is because fixing errors like memory leaks necessitates an understanding of heap-related behavior, such as error source and sink. Collecting heap-related behavior information needs a high time and space overhead. Because wrong patches or fixing locations might lead to more significant errors, and different heap objects can interact with each other, all of this must be fully considered when generating patches. The state-of-the-art automated memory error repair technology SAVER~\cite{SAVER} stores these heap-related behaviors by constructing an object flow graph, which has high time and space complexity. However, because static analysis techniques are not good at dealing with problems such as indirect calls and alias, the repair tools based on static analysis might generate the wrong patches. While dynamic analysis can detect memory errors efficiently by instrumenting the critical program points to observe the legality of program behavior during execution, it does not provide enough information to generate patches.

In this paper, we present \textbf{HAMER}, a hybrid analysis-based memory error repair \mbox{technique}. We use a static analyzer to detect the program first, then use a fuzzer to detect the alarms and extract the real errors. Fuzzer triggers runtime errors, thus it will not give false-positive alarms, allowing HAMER to avoid trying to fix wrong alarms. After that, we collect program variables that can be utilized to synthesize patches by variable dependency analysis. During this procedure, we also collect the return locations of each function as the candidate fix locations. With this lightweight static analysis, HAMER is able to obtain enough information to fix the buggy program. We then gather the test cases generated by the fuzzer which trigger or do not trigger the errors and use the component-based program synthesis~\cite{oracle} to try to generate patches from these variables and test cases. Finally, we utilize the fuzzer to verify the current fixed program, and if the repair is erroneous, we collect the test case that triggers the errors and repeat our repair method until the error is fixed or timeout. This strategy ensures that the patches generated by HAMER can repair current errors without introducing new ones. Our preliminary experiment suggests that HAMER can fix the complicated memory errors effectively, which the existing static memory error repair technique cannot repair. It also shows that our lightweight static analysis can collect enough information in a short time to assist HAMER to generate the correct patches.

\textbf{Contributions.} This paper makes the following contributions:
\begin{itemize}
  \item We present a new technique for repairing memory errors based on hybrid analysis. We present an efficient repair algorithm that only needs lightweight static analysis to collect relevant information and makes flexible use of the fuzzer's result to generate and verify patches. Also, our technique can generate and insert conditional deallocation patches correctly and can fix multiple memory leaks at the same time.
  \item We present HAMER~\footnote{https://github.com/QIANZECHANG/HAMER}, a memory error repair tool that implements the proposed approach.
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Background}

HAMER detects bugs using existing bug detection tools. In this section, we will introduce the static analyzer (Infer~\cite{infer}~\footnote{https://fbinfer.com/}) and fuzzer (LibFuzzer~\footnote{https://llvm.org/docs/LibFuzzer.html}) that HAMER uses. We also introduce the component-based program synthesis (CBPS)~\cite{oracle} which we use to synthesize the patches. 

\section{Infer}

Infer is a static program analyzer for Java, C, and Objective-C, written in OCaml, developed by Facebook. Infer is a high-performance static analyzer with high scalability and efficiency, and it is widely used by programmers and researchers. Infer automatically discovers specifications for the functions that can be proven to be memory safe using the theoretical notion of bi-abductive inference~\cite{bi}. The bi-abductive inference can generate the specification of a function's heap-related behavior and can be directly used to analyze the heap situation whenever the function is called.

For example, in Figure~\ref{inferexample}, the $foo$ function dynamically allocates memory through the $alloc$ function. Infer uses bi-abductive inference to approximate the procedures' heap behavior, so Infer does not determine that $alloc$ occurs memory leak because $alloc$ returns $p$, meaning that $p$ is not unreachable and the responsibility for freeing $p$ is transferred to $foo$. Infer will construct the specification of $alloc$ using these heap features and use it to analyze other procedures when $alloc$ is called. Therefore, in $foo$, $p$ gets the return of $alloc$ and has not been freed until last, Infer determines that $foo$ occurs memory leak.

\begin{figure}[h]
    \lstinputlisting[xleftmargin=0.25\textwidth,linewidth=0.75\textwidth]{infer.c}
    \caption{Example of Infer}
    \label{inferexample}
\end{figure}

However, Infer is hard to handle some issues, such as indirect call and alias, which causes Infer to provide false-negative and false-positive alarms. As a result of this shortcoming, automated repair tools may waste time on the wrong alarms (false-positive) and have no opportunity to fix the errors that are not discovered (false-negative).


\section{LibFuzzer}


LibFuzzer can be described as an evolutionary fuzzing engine and is both in-process and coverage-guided. LibFuzzer relies on an entry point to feed a fuzzy input to the function, which is often referred to as the target function. LibFuzzer can then track to a certain area and aim to explore more areas, generating the variant form of the input data mentioned above. The advantage of this is that it can obtain maximum code coverage.  To check the code coverage, the information provided by SanitizerCoverage~\footnote{https://clang.llvm.org/docs/SanitizerCoverage.html} is used by LibFuzzer.

LibFuzzer uses the information provided by the AddressSanitizer~\cite{asan}~\footnote{https://clang.llvm.org/docs/AddressSanitizer.html} and the LeakSanitizer~\footnote{https://clang.llvm.org/docs/LeakSanitizer.html} to determine if an error has happened within the detected code coverage when detecting memory errors. AddressSanitizer uses a shadow memory to encode the allocated space (address and size) and verifies the legality each time the space is accessed. AddressSanitizer instruments every heap-related behavior (such as allocation, deallocation, read, and write) during compile-time and checks the legality of the behavior that the memory is being read/written, by checking the shadow memory's data during program execution. While LeakSanitizer stores the allocation thread ID and the allocation stack itself each time memory is allocated and records the situation when memory is deallocated. At the very end of program execution, LeakSanitizer will go over the heap to find out such objects that have not been freed.

LibFuzzer mutates the data based on a corpus of input samples of the tested codes. In general, a good corpus is seeded with different sets of valid and invalid inputs of the detection code. The fuzzer generates random mutations based on the input samples from the corpus in use at the moment. If this random mutation triggers an error in the detection code and the source of this erroneous path is a previously undiscovered path, then this random mutation is saved to the corpus we have set. The advantage of LibFuzzer is that it can work without any initial seed. The weakness on the other hand is that if the library being examined requires complex and structured input, then LibFuzzer's efficiency is subsequently somewhat reduced.

Because LibFuzzer can only fuzz test one function argument at a time, we must test each argument independently for functions with multiple arguments. LibFuzzer may take a long time or fail to mutate the inputs that can go into each path for the functions that need complex inputs. Furthermore, LibFuzzer will stop and report errors anytime it triggers the error, thus if a function has several errors in different paths, LibFuzzer cannot ensure that all of them will be detected at the same time. The code below, for example, has two memory leaks. 

\begin{minipage}{\textwidth}
    \vspace{0.2cm}
    \hspace{0.3cm}\verb|p1=malloc(1);|\\\hspace{0.3cm}\verb|if(a<5)p2=malloc(1);|\\
\end{minipage}
The ideal situation would be for LibFuzzer to input the value smaller than 5 and trigger both errors. But in most cases,  LibFuzzer inputs other values only triggers the memory leak of {\it p1} and then exits. As a result, LibFuzzer may not be able to detect all of the errors in a function at the same time (although it has the ability to do). Although LibFuzzer can detect memory errors efficiently, it cannot provide enough information for repair tools to generate patches. For example, even though LibFuzzer inputs \verb|a=3| and triggers both errors, we can not figure out what is the correct conditionals of the patches and where to insert the patches.

\section{Component-Based Program Synthesis}

Component-based program synthesis can synthesize the program that satisfies the test suite using given components, which means, if given an input-output pair$(a,b)$, the synthesized program should output b when input a. In component-based program synthesis, we use a set of basic components (constant, operators, program variables) to synthesize the expected expression. For example, to synthesize an expression using components $(constant, -, +)$ and program variables $(x, y)$, we can synthesize the following expressions. 

\begin{minipage}{\textwidth}
    \vspace{0.2cm}
    \hspace{0.3cm}\verb|x+y, x-y, y-x, x+c, x-c, c-x, y+c, y-c, c-y|\\
\end{minipage}
We use the components to synthesize the candidate expression and construct the constraint using the test suite. The constraint is in first-order logic and solved by an SMT solver. If it is satisfiable, the expression can be constructed. 

\begin{equation}
\label{constraint}
\theta=\bigwedge_{i,o\in T}^{}\varphi(\psi(e),i,o)
\end{equation}

Formula~\ref{constraint} denotes the formal definition of the CBPS constraint. $\psi(e)$ denotes that the synthesized expression $e$ should be a well-formed expression that satisfied the specification of the operator and $i,o$ is an input-output pair of test suite $T$. $\varphi(\psi(e),i,o)$ denotes that when $e$ inputed $i$, the output must be $o$. Finally, the constraint $\theta$ represents that $e$ must be a well-formed expression and given test suite $T$, $e$ should satisfy all input-output pairs in it.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Overview}
\label{overview}
We illustrate key features of HAMER and how it works. Figure~\ref{pipeline} depicts a high-level overview of the HAMER pipeline.

First, we check the program with the static analyzer \mbox{Infer}, and then we manually collect the functions that contain Infer alarms. Following that, these functions are fuzzed by LibFuzzer to detect true errors.  For those functions on the error path, we collect the variables that are dependent on the function arguments and stub them. Dependent variables will be used to synthesize the conditional of the patch. After that, we instrument all of the dependent variables and run the program via LibFuzzer to collect the tests that do or do not trigger the error. Finally, we use a simplified component-based program synthesis (simp-CBPS) to generate patches. Because the quality of the test suite affects the quality of the patch, we use LibFuzzer to check the current fixed code again, and if it has not been fixed or if a new error occurs, we collect the tests that cause the error or insert the patch in a different location. This strategy ensures that the patches generated by HAMER are correct and do not introduce new errors. In the following paragraphs of this section, we will use two motivating examples to demonstrate the workflow and characteristics of HAMER.

%----------------pipeline-----------------------------------
\tikzstyle{tool} = [diamond, draw, fill=green!20, text centered, text width=4.5em, aspect=2]
\tikzstyle{block} = [rectangle, draw, fill=blue!20, text width=7em, rounded corners, minimum height=3em]
\tikzstyle{block2} = [rectangle, draw, fill=blue!20, text centered, text width=7em, rounded corners, minimum height=3em]
\tikzstyle{line} = [thick,->,>=stealth]
\tikzstyle{outdata} = [rectangle, draw, fill=brown!20, text width=5em, minimum height=3em]
\tikzstyle{code} = [draw, ellipse,fill=red!20, text width=2em, minimum height=3em]
\tikzstyle{bigcode} = [draw, ellipse,fill=red!20, text width=5.5em, minimum height=3em]
\tikzstyle{midcode} = [draw, ellipse,fill=red!20, text width=4.5em, minimum height=3em]
\begin{figure*}[ht]
\hspace{-0.5cm}
\begin{tikzpicture}[node distance = 3.5cm, on grid]
  %node
  \node[tool] (infer){Infer};
  \node[code, below of=infer,yshift=1.5cm] (src){src.c};
  \node[outdata, right of=infer] (efunc){error\\functions};
  \node[tool, right of=src] (fuzzer1){LibFuzzer};
  \node[outdata, below of=fuzzer1, yshift=1.5cm] (error){true errors};
  \node[block, below of=error,yshift=2cm] (dep){Dependency\\Collection};
  \node[outdata, right of=dep] (depvar){dependent\\variables};
  \node[block, right of=error,yshift=1cm] (inst){Source\\Instrumentation};
  \node[bigcode, right of=fuzzer1,yshift=1cm] (instcode){Instrumented\\code};
  \node[tool, right of=instcode] (fuzzer2){LibFuzzer};
  \node[outdata, right of=inst] (test){test suite};
  \node[block2, right of=depvar] (syn){simp-CBPS};
  \node[midcode, right of=syn] (fix){current\\fixed code};
  \node[code, above of=fuzzer2,yshift=-1.5cm] (output){out.c};
  \node[right of=output,yshift=-1cm,xshift=-2.5cm] (no){no error}; 
  \node[below of=no,yshift=1.5cm,xshift=-0.3cm] (yes){error}; 
 %edge
  \draw [line] (src) -- (infer);
  \draw [line] (src) -- (fuzzer1);
  \draw [line] (infer) -- (efunc);
  \draw [line] (efunc) -- (fuzzer1);
  \draw [line] (fuzzer1) -- (error);
  \draw [line] (error) -- (dep);
  \draw [line] (src) |- (dep);
  \draw [line] (dep) -- (depvar);
  \draw [line] (depvar) -- (inst);
  \draw [line] (inst) -- (instcode);
  \draw [line] (instcode) -- (fuzzer2);
  \draw [line] (fuzzer2) -- (test);
  \draw [line] (test) -- (syn);
  \draw [line] (depvar) -- (syn);
  \draw [line] (syn) -- (fix);
  \draw [line] (fix) |- (fuzzer2);
  \draw [line] (fuzzer2) -- (output);
  \draw [line] (src) |- (inst);
\end{tikzpicture}
  \caption{HAMER pipeline}
  \label{pipeline}
\end{figure*}
%----------------code---------------------------

\begin{figure*}
  \begin{subfigure}{0.47\textwidth}
    \lstinputlisting{me1a.c}
    \caption{o0, o1, o2 occur memory leak}
    \label{me1a}
  \end{subfigure}\hfill
  \begin{subfigure}{0.45\textwidth}
    \lstinputlisting[firstline=17,firstnumber=17]{me1b.c}
    \caption{HAMER-generated patch}
    \label{me1b}
  \end{subfigure}
  \caption{Motivating Example 1: Infer false-negative alarm} 
  \label{me1}
\end{figure*}

\begin{figure*}
  \begin{subfigure}{0.47\textwidth}
    \lstinputlisting{me2a.c}
    \caption{No memory leak}
  \end{subfigure}\hfill
  \begin{subfigure}{0.45\textwidth}
    \lstinputlisting{me2b.c}
    \caption{SAVER-generated patch}
  \end{subfigure}
  \caption{Motivating Example 2: Infer false-positive alarm}
  \label{me2}
\end{figure*}

\section{Motivating Example 1}
This buggy code has three error heap objects, denoted by {\it o0}, {\it o1}, and {\it o2}, as shown in Figure~\ref{me1a}. First, we use Infer to detect this code, obtaining the following result:

\begin{minipage}{\textwidth}
\vspace{0.2cm}
\textsl{\hspace{0.3cm}Object allocated at line 20 is unreachable at line 20.\\}
\end{minipage}

Because static analyzers like Infer have a difficult time resolving issues like indirect calls, they can only detect the memory leak of {\it o2}. After we received the Infer results, the error function was detected again by LibFuzzer, and all errors were successfully detected. For example, for {\it o1}, we can get the fuzzing result shown below:


\begin{minipage}{\textwidth}
    \vspace{0.2cm}
    \textsl{\hspace{0.3cm}in malloc ../a.out\\\hspace{0.3cm}in new\_node2 ../src.c:12:18\\\hspace{0.3cm}in func ../src.c:23:7\\}
\end{minipage}

We can get all of the functions on the error path using LibFuzzer. Obviously, the correct fix location could be in any of the functions, so we collect the variables that are dependent on the function argument, and we also collect both the heap object information and the return location of each function during this static analysis. 

\begin{table}[h]
  \caption{Instrumentation result of o1}
  \label{instres}
  \centering
  \begin{tabular}{|c|c|c|c|}
    \hline
    func  & \multicolumn{2}{|c|}{new\_node2} & \multirow{2}{*}{error} \\
    \cline{1-3}
    a & a & n\verb|->|v &\\
    \hline
     0 & 0  & 0 & 1\\
     5 & 5  & 25 & 0\\
     6 & 6  & 36 & 0\\
     8 & 8  & 64 & 0\\
    \hline
  \end{tabular}
\end{table}

Following that, we instrument all of the dependent variables and run the source instrumented code through Libfuzzer to collect dynamic values for each dependent variable. Table~\ref{instres} displays the results of {\it o1}'s collection. The {\it error} column indicates whether or not memory leak occurred at the current value, with 1 indicating that it did and 0 indicating that it did not. Table~\ref{instres} shows that {\it o1} leaks when the variable {\it a} in the function {\it func} is less than or equal to 4. We can synthesize the ideal patch using simp-CBPS, which is:

\begin{minipage}{\textwidth}
\vspace{0.2cm}
\hspace{0.3cm}
\raggedright
\verb|if(a<=4)free(o1);|
\label{patch1}
\vspace{0.2cm}
\end{minipage}

Finally, we use LibFuzzer to detect the patched code, and if it fixes the current bug, we keep the patch and fix other bugs until all bugs are fixed or time out. If the current patch does not fix the bug or causes a new bug, we try to insert the patch into another location or collect new tests to synthesize a new patch. For example, we can also synthesize patches like \verb|if(a<=3)free(o1);| using the Table~\ref{instres} results. With Libfuzzer, we can see that when \verb|a=4|, {\it o1} still occurs memory leak. We will start by trying alternative fix locations, however, because the function {\it func} only has one return place, we can only collect new tests to synthesize a new patch. We add $(a:4, error:1)$ to the test suite and then use the synthesizer to generate a new patch. It's self-evident that the improved test suite enabled us to obtain the correct patch. We will utilize temporary variables to save the heap object and variables in the conditional when we apply the patch. This step is necessary to prevent these variables from changing between the allocation location and patch insertion location.

Although it is possible to fix the  {\it o1} memory leak by inserting a patch into function  {\it new\_node2}, the use-after-free problem will occur if the memory is freed too early due to the use of  \verb|x->v| at line 25 of the function  {\it func}.



%---------------------------------------------
%[+] { Insert: if (true) free(*(func:x.p2)) at 3 (line 12, column 3) }
% memory dynamically allocated to `y` by call to `malloc()` at line 20, column 11 is not reachable after line 20, column 3.

%------------------------------------------------------
\section{Motivating Example 2}
We briefly discussed how HAMER uses fuzzing (LibFuzzer) to detect and fix errors that are not noticed by the static analyzer (Infer) in Motivating Example 1. Similarly, HAMER can avoid attempting to resolve false alarms. In Motivating Example 2, line 10 frees {\it o1} in some other way, but Infer misses it, so it assumes {\it o1} occurs memory leak. SAVER~\cite{SAVER} also ignores the fact that this is a false alarm and generates the incorrect patch, resulting in {\it double-free}. HAMER utilizes LibFuzzer to dynamically detect code, and LibFuzzer does not report issues for Motivating Example 2, therefore HAMER saves time trying to generate a fix for the wrong alarm. However, depending on the complexity of the function argument and the fuzzer's mutation strategy, the fuzzer may fail to visit the error path.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Approach}
\label{approach}
In this section, we describe our approach in detail, explaining what technical issues arise and how we address them. There are three major issues to consider:
\begin{itemize}
\item It is difficult for LibFuzzer to directly collect the high-quality test suite. How can HAMER synthesize the correct conditional?
\item How does HAMER choose the correct fix location(s) when a function has multiple return places?
\item How does HAMER deal with several memory errors in a single function?
\end{itemize}

HAMER will solve these issues by using LibFuzzer to constantly check the patched code. In section~\ref{patchgeneration}, we will go over our repair algorithm in detail. Until then, we will describe how HAMER gathers the data required to fix the errors.

\section{Patch Template}
The purpose of this research is to fix temporal memory errors such as memory leaks, not spatial memory errors such as buffer overflow. The most common solution for temporal memory errors is to free the memory at the correct location. As a result, the following patch template can fix most of the temporal memory errors.


\begin{minipage}{\textwidth}
    \vspace{0.2cm}
    \hspace{0.3cm}\verb|if(cond)free(ob);|\\
\end{minipage}
We can free the specified heap object under the specific condition by inserting a conditional deallocator. Hence, in order to generate the correct patch, we should know the following three details:
\begin{itemize}
  \item[(1)] conditional $cond$
  \item[(2)] error heap object $ob$
  \item[(3)] fix location
\end{itemize}
We will present in detail how we generated the correct patch in the following subsection.

\section{Error Detection}
HAMER uses a static analyzer to find functions that may have memory errors and then uses fuzzer to detect the real errors in those functions. The purpose of applying the static analyzer is to improve HAMER's scalability, as the fuzzer always takes a long time to detect errors. Using the static analyzer to pick out candidate functions prevents fuzzer from wasting time in locations where it is not necessary. But obviously, HAMER will not be able to fix errors in functions that are not provided by the static analyzer. So for shortcode, we can just simply use fuzzer to detect errors. After error detection, we can obtain a set $E$ that contains the details of each error reported by fuzzer, similar to the report shown in Motivating Example 1.


\section{Dependency Collection}


We collect the error paths and error heap objects for each element in the set $E$ separately after obtaining the error report $E$. We can organize the information of each error from the error report to produce the set $EP$ using the error paths and coordinates provided by LibFuzzer. 


\begin{equation}
EP=\{get\_path(e)|\, e \epsilon E\}
\end{equation}
In Motivating Example 1 (Figure~\ref{me1}), LibFuzzer gives the error report of $o1$, and we can obtain the error path of $o1$:


\begin{minipage}{\textwidth}
\vspace{0.2cm}
\textsl{\hspace{0.3cm}\{funcname: func, coord: src.c:23:7, next:\\\hspace{0.6cm}\{funcname: new\_node2, coord: src.c:12:18, next:\\\hspace{0.9cm}\{funcname: malloc\}\}\}}
\vspace{0.2cm}
\end{minipage}
It is worthy to note that the $coord$ of each function is the error location inside the function, not the function's coordinate. All error paths, obviously, will end with an allocation function, and the coordinates of the allocation function will be kept in the previous node's $coord$, which we will use to localize the error heap object.


After organizing the error report, we collect the dependent variables in each function on the error path, which are utilized to synthesize the conditional. Fuzzer tries to trigger the function's error by inputting different data, so all the variables in the function that are dependent on the argument could be utilized to synthesize the patch's conditional. These dependent variables are collected using {\it def-use} chain, and their names, types, and coordinates are saved. During this static analysis, we also gather the return location of each function, as well as the name and type of the error heap object.



As we present in the Background, fixing the temporal memory error requires inserting the deallocation at the correct location. A memory leak will occur if allocated memory space is not freed at the end of the program, hence it is critical to free allocated memory before it is unreachable. Most of the existing memory error repair techniques~\cite{SAVER, Memfix} are based on static analysis that collects heap-related behavior, so they can insert the patch at the right location. However, the tradeoff is that it requires a high overhead, and static analysis is tough to deal with some problems such as indirect call, which may make repair tools fail to generate a patch or generate a wrong patch. HAMER aims to collect the essential information for fixing errors via lightweight static analysis. There are three major reasons why allocated memory cannot be accessed: (1) it is freed, (2) no pointer points to it, and (3) the current function exits. Memory leaks will not occur if it is properly freed. For the second reason, we will use a temporary variable to save the pointer to the error memory when it is allocated, as we will explain in detail in subsection~\ref{patchgeneration}. Hence,  we simply need to think about the third reason. A function may exit in two ways: by {\it return} or by exiting automatically at the end of the function. As a result, we just need to collect all of each function's {\it return} locations, as well as the location of the function tail, and use them as the candidate fixing location.



We extract the name and type of error heap objects at the location detected by the fuzzer. Its type is mainly determined by three factors: (1) declaration type, (2) casting type, and (3) type in the $sizeof$. For instance, the following code demonstrates how developers use $malloc$ for memory allocation:


\begin{minipage}{\textwidth}
\vspace{0.2cm}
\hspace{0.3cm}\verb|int* p=(int*)malloc(sizeof(int));|
\vspace{0.2cm}
\end{minipage}
We only need one of these to determine the type of the heap object, but there are indeed cases where all three are not written, such as when type is defined in a structure and then cast and sizeof are not used:


\begin{minipage}{\textwidth}
\vspace{0.2cm}
\hspace{0.3cm}\verb|x->v=malloc (4);|
\vspace{0.2cm}
\end{minipage}
In such cases, HAMER is unable to obtain their type, however, this is not a weakness of our approach. HAMER employs lightweight static analysis that can handle most cases. If we want to achieve higher performance, we can employ a more precise type analysis, but the tradeoff is higher overhead.


Finally, we formalized the dependency information $Dep$ as follows:

\begin{equation}
Dep=\{(get\_dep(path),\,get\_ret(path),\,get\_ob(path))|\, path \epsilon EP\}
\end{equation}

\section{Source Instrumentation}
We apply source instrumentation on the dependent variables after obtaining them in order to collect their dynamic values and build a test suite. A common test suite consists of several $input-output$ pairs; however, because the goal of our technique is to fix memory leaks, each $input$ corresponds to an $output$ that indicates whether or not the $input$ will trigger the error; if it does, the output is 1, otherwise, it is 0. For example, our instrumented code for the variable $a$ of the $func$ function in Figure~\ref{me1a} is as below:


\begin{minipage}{\textwidth}
\vspace{0.2cm}
\hspace{0.3cm}\verb|fprintf(stderr,"instrument:(line:17) a:%d\n",a);|
\vspace{0.2cm}
\end{minipage}
We record the locations of the variables to identify their values because the same variables will have different values at different locations. Because the results of LibFuzzer are sent to $stderr$, we also send the results of the instrumentation to $stderr$ and combine them with the results of LibFuzzer.


Our approach's overall concept of source instrumentation and dynamic values collection is shown in Algorithm~\ref{algo1}. We create a new set $SynInf$ to contain the information about fixing each error. We first define a set $dep\_var$ to store all the dependent variables in $Dep$ and for different errors, we save the dependent variables $Var$, return location $Ret$, and error heap object information $ob$ to $SynInf$. To get enough data, we use LibFuzzer to run the instrumented code 10 times and collect data for different errors. If the current execution results trigger an error, we set the $output$ of the triggered error's dependent variable to 1, otherwise, we set it to 0.


 \begin{algorithm}[t]
 \caption{Source Instrumentation Result Collection}
 \label{algo1}
 \begin{algorithmic}[1]
 \renewcommand{\algorithmicrequire}{\textbf{Input:}}
 \renewcommand{\algorithmicensure}{\textbf{Output:}}
 \REQUIRE src, Dep
 \ENSURE  SynInf
  \STATE $dep\_var \gets \emptyset$
  \STATE $SynInf \gets \emptyset$
  \STATE $err\_id \gets 0$
  \FOR {$(Var, Ret, ob) \in Dep$}
   \STATE $dep\_var \gets dep\_var \cup Var$
   \STATE $SynInf[err\_id].add((Var,Ret,ob))$
   \STATE $err\_id \gets err\_id + 1$
  \ENDFOR
  \STATE $inst\_code \gets \textbf{Instrument}(src, dep\_var)$
  \STATE $i \gets 0$
  \WHILE {$i < 10$}
   \STATE $res \gets \textbf{Fuzz}(inst\_code)$
    \FOR {$err\_id = 0$ to $|Dep|-1$}
     \FOR {$var \in dep\_var$}
     \IF {$memory$ $leak$ $happen$}
      \STATE $SynInf[err\_id][var].add((res[var],1))$
     \ELSE
      \STATE $SynInf[err\_id][var].add((res[var],0))$
     \ENDIF
     \ENDFOR
    \ENDFOR
   \STATE $i\gets i + 1$
  \ENDWHILE
 \end{algorithmic} 
 \end{algorithm}

\section{Patch Generation}
\label{patchgeneration}

In this section, we will present our repair algorithm and demonstrate how our repair algorithm solves the major issues we mentioned before.


\subsection{simp-CBPS}
Since we only need to synthesize the conditional of deallocation, we use a simplified version of component-based program synthesis~\cite{oracle} (simp-CBPS). In simp-CBPS, a component is a variable, a constant, or an operator. simp-CBPS uses these user-given components to generate code that satisfies the test suite. 

For example, we use the following components to synthesize code that satisfies the test suite in Table~\ref{test}.


\begin{minipage}{\textwidth}
    \vspace{0.2cm}
    \textsl{\hspace{0.3cm}variable: x\\\hspace{0.3cm}constant: c\\\hspace{0.3cm}operator: $*_1<*_2$\\}
\end{minipage}
Since $<$ is a binary operator, we can construct the expression \verb|x<c| and \verb|c<x| using the variable $x$ and the constant $c$. Then we assign the value from Table~\ref{test} to get the logical formula below:


\begin{minipage}{\textwidth}
    \vspace{0.2cm}
    \textsl{\hspace{0.3cm}$x<c: (4<c)\wedge(5<c)\wedge\neg(6<c)\wedge\neg(7<c)$\\\hspace{0.3cm}$c<x: (c<4)\wedge(c<5)\wedge\neg(c<6)\wedge\neg(c<7)$\\}
\end{minipage}
We have turned the program synthesis problem into {\it Satisfiability Modulo Theories} (SMT) by doing the above action. We solve the logical formula via the SMT solver. If a logical formula is unsatisfiable, it means that the present synthesized expression does not pass the test suite, indicating that it is not the expected expression. For example, the second logical formula is unsatisfiable, hence \verb|c<x| is not the correct expression. The first logical formula is satisfiable and the result is \verb|c=6|, so we can get the expected expression \verb|x<6|.


\begin{table}[h]
  \caption{Test suite}
  \label{test}
  \centering
  \begin{tabular}{|c|c|}
    \hline
     x & output \\
    \hline
     4 & True \\
     5 & True \\
     6 & False \\
     7 & False \\
    \hline
  \end{tabular}
\end{table}

The quality of the test suite is the most critical part of using CBPS to synthesize expressions. CBPS will synthesize incorrect expressions if the test suite provided by the user is of poor quality. If Table~\ref{test} does not have $(x=6, output=False)$, for example, we might obtain \verb|x<7|. Obviously, CBPS can only synthesize numeric expressions.


\subsection{Repair Algorithm}
The input of our repair algorithm (Algorithm~\ref{repalgo}) is the source code and the collected information $SynInf$, and the output is the fixed code generated by HAMER. We use a $queue$ to keep the number of each error and repair them one by one. When repairing, we first pop an error number from the $queue$ and then get the corresponding information from $SynInf$. After that, we synthesize the conditional of the patch using simp-CBPS. Because all the functions on the error path have the potential to become the fix location, simp-CBPS synthesizes all satisfiable patches, and the fix location and heap object information corresponding to the patch are gathered and saved to {\it cur\_patches}.


After that, we synthesize the patch and use the function $Fix$ (Algorithm~\ref{funcfix}) to insert it in the right location. If the currently generated patch fails to fix the error, we gather the test that triggers the error and append it to the test suite. For example, when HAMER fixes the memory leak of {\it o1} in Figure~\ref{me1a} of Motivating Example1, it's difficult to collect enough tests directly, thus the next two incorrect patches could be synthesized:


\begin{minipage}{\textwidth}
    \vspace{0.2cm}
    \hspace{0.3cm}(1) \verb|if (a<=3)free(o1);|\\\hspace{0.3cm}(2) \verb|if (a<=5)free(o1);|
\end{minipage}
If simp-CBPS does not get the test $(a:4, error:1)$, it will synthesize the conditional of the first wrong patch, and if it does not get the test $(a:5, error:0)$, it will synthesize the conditional of the second wrong patch. For the first patch, we can get that memory leak will happen when \verb|a=4| via LibFuzzer, so we add $(a:4, error:1)$ to the test suite. For the second patch, when \verb|a=5|, since {\it o1} is not defined yet, free it is undefined behavior, so we add $(a:5, error:0)$ to the test suite. Similarly, if a test triggers a double free, we will add this test and $(error:0)$ to the test suite, indicating that this heap object has already been deallocated at this test.


We keep the patch of the current error if this error is fixed, and we clear the test suite in $SynInf$ if there are still have errors to be fixed. The goal of this step is to save space and speed up the SMT solver computation. $SynInf$ takes up a lot of space because the test suite is constantly updated. The quality of the gathered test suite will also be affected if a function has several errors. We can recollect the test suite when an error is fixed to receive a higher-quality test suite and save space. If the current error is not fixed, we add the error number to the queue and try to fix it later.



To ensure that our algorithm terminates at the right time, we use two methods. The first occurs in line 9. If simp-CBPS synthesizes the same patch as last time, indicating that this error is difficult to fix in the current situation. In most cases, we are unable to collect a high-quality test suite due to multiple errors in the function, so we give up trying to fix this error for the time being and return to it after fixing other, much simpler errors. The second is that we create an $unfixederror$ variable to keep track of errors that we try to fix but can not. Because there may sometimes be several errors that HAMER cannot solve, we stop HAMER if none of the remaining errors are fixed after HAMER tries to fix them.


 \begin{algorithm}[t]
 \caption{Repair Algorithm}
 \label{repalgo}
 \begin{algorithmic}[1]
 \renewcommand{\algorithmicrequire}{\textbf{Input:}}
 \renewcommand{\algorithmicensure}{\textbf{Output:}}
 \REQUIRE src, SynInf
 \ENSURE  fixed\_code
  \STATE $fixed\_code \gets src$
  \STATE $queue \gets \{0,1,...,|SynInf|-1\}$
  \STATE $unfixederror = 0$
  \WHILE {$|queue| \ne 0 $ and $unfixederror \ne |queue| $}
   \STATE $err\_id \gets queue.pop$
   \STATE $err\_inf \gets SynInf[err\_id]$
   \REPEAT
    \STATE $cur\_patches \gets \textbf{simp-CBPS}(err\_inf)$
    \IF {$cur\_patches$ $same$ $as$ $last$ $time$}
     \STATE $\textbf{break}$
    \ENDIF
    \STATE $cur\_code \gets \textbf{Fix}(cur\_patches,fixed\_code)$
    \IF {$not$ $fixed$}
     \STATE $err\_inf \gets \textbf{Update}(err\_inf)$
    \ENDIF
   \UNTIL {$timeout$ or $error$ $fixed$}
   \IF {$current$ $error$ $fixed$}
    \STATE $fixed\_code \gets cur\_code$
    \STATE $unfixederror \gets 0$
    \IF {$queue$ $is$ $not$ $empty$}
     \STATE $SynInf \gets \textbf{Clean}(SynInf)$
     \STATE $SynInf \gets \textbf{Update}(SynInf)$
    \ENDIF
   \ELSE
    \STATE $queue.add(err\_id)$
    \STATE $unfixederror \gets unfixederror + 1$
   \ENDIF
  \ENDWHILE  
 \end{algorithmic} 
 \end{algorithm}


\subsection{Function Fix}
It is critical to insert the patch in the correct location in order to fix temporal memory errors. Function $Fix$ to determine if the fix location is correct. We test the patch and the fix location of each function on the error path one by one. Fuzzer checks a patch when it is inserted into a fix location. If the patch introduces a new error in the existing fix location, it is clear that the fix location is incorrect, and we should try a different fix location. If no new errors are raised but the existing error remains unfixed, it is possible that the current fix location only partially fixed the error; in that case, we save the patch inserted at the current fix location and try other fix locations. The following code, for example, has two returns, and we must apply the patch to both of them to fix the error.


\begin{minipage}{\textwidth}
    \vspace{0.2cm}
    \hspace{0.3cm}\verb|p=malloc(1);|\\\hspace{0.3cm}\verb|if(c){|\\\hspace{0.6cm}\verb|use(p);|\\\hspace{0.6cm}\verb|return 0;|\\\hspace{0.3cm}\verb|}else{|\\\hspace{0.6cm}\verb|use(p);|\\\hspace{0.6cm}\verb|return 1;|\\\hspace{0.3cm}\verb|}|
    \vspace{0.2cm}
\end{minipage}
The memory leak was not fixed when we inserted the patch before the first $return$, so we kept the current patch and inserted the patch before the second $return$, and then the error was correctly fixed.



 \begin{algorithm}[h]
 \caption{Function Fix}
 \label{funcfix}
 \begin{algorithmic}[1]
 \renewcommand{\algorithmicrequire}{\textbf{Input:}}
 \renewcommand{\algorithmicensure}{\textbf{Output:}}
 \REQUIRE cur\_patches, code
 \ENSURE  fixed\_code
  \STATE $test\_code \gets code$
  \FOR {$(cur\_patch,Ret) \in cur\_patches$}
   \FOR {$retloc \in Ret$}
    \STATE $test\_code \gets \textbf{InsertPatch}((cur\_patch,retloc))$
    \STATE $\textbf{Fuzz}(test\_code)$
    \IF {$new$ $error$ $occurs$}
     \STATE $test\_code \gets code$
     \STATE $\textbf{continue}$
    \ELSIF {$same$ $error$ $occurs$}
     \STATE $\textbf{continue}$
    \ELSE 
     \STATE $\textbf{return}$ $test\_code$
    \ENDIF
   \ENDFOR
  \ENDFOR
  \STATE $\textbf{return}$ $\emptyset$
 \end{algorithmic} 
 \end{algorithm}

\subsection{Temporary Variable}
We use temporary variables to store the variables used in the patch conditional and the error heap object while inserting patches. Because the values of these significant variables may modify between the error source and the fix location, analyzing these changes requires complex static analysis. To address this issue without increasing the complexity of our algorithm, we use temporary variables to store the values of these variables, so that even if their values changed, the patches generated by HAMER are still correct (e.g., Figure~\ref{me1b}).


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Evaluation}
We evaluate the effectiveness and efficiency of HAMER and answer the following research questions.

\begin{itemize}
\item[\textbf{RQ1}] Compared with state-of-the-art automated memory error repair tool SAVER, what is the overall effectiveness of HAMER?
\item[\textbf{RQ2}] Can HAMER address the three major issues we mentioned in Chapter~\ref{approach}? 
\item[\textbf{RQ3}] How efficient is HAMER in using lightweight static analysis?
\end{itemize}

\section{Implementation}
We have implemented our approach in a tool named ExtractFix, whose pipeline is shown in Figure~\ref{pipeline}. HAMER detects the memory leak in the program using existing vulnerability detection tools. To detect the real errors, HAMER first uses a static analyzer to detect the program, then uses a fuzzer to detect static analyzer alarms. The main role of the static analyzer is to filter out the problematic functions in the program so that the fuzzer does not waste time on other parts. We directly use a fuzzer to verify the code in our experiments because we utilize short code examples to test the efficiency of HAMER. We use LibFuzzer to perform the fuzz testing. Since LibFuzzer may not detect all of the errors, we fuzz code 10 times each time. If LibFuzzer does not detect an error within 5 seconds for one execution, the code is judged no error (or fixed). The input data format is set to an integer of two digits or less. HAMER is written in 1000 lines of python3 code. For syntactic analysis of $c$, we use the pycparser module~\footnote{https://github.com/eliben/pycparser}. In our implementation of simp-CBPS, we use the Z3~\cite{z3} python module~\footnote{https://github.com/Z3Prover/z3} as the SMT solver and implemented six operators (\verb|!=|, \verb|==|, \verb|<|, \verb|<=|, \verb|>|, \verb|>=|) as components. 

\section{Experimental Setup}
To analyze HAMER, we synthesized 11 codes. Because HAMER's scalability is currently limited, and memory leaks in real-world projects can not properly reflect HAMER's properties, we gave up utilizing real-world projects to evaluate HAMER. These codes were synthesized from six different directions, as shown in Table~\ref{syncode}. To fuzz the code, LibFuzzer requires an entry point, which we manually added to the code as shown below. 

\begin{minipage}{\textwidth}
    \vspace{0.2cm}
    \textsl{\hspace{0.3cm}int LLVMFuzzerTestOneInput(char *data, int size) \{\\\hspace{0.6cm}ConvertChartoInt(data);\\\hspace{0.6cm}EntryPoint(data);\\\hspace{0.6cm}return 0;\\\hspace{0.3cm}\}}
    \vspace{0.2cm}
\end{minipage}
HAMER's static analysis and fuzzing time were also observed during the experiment. Since the repair process of HAMER was not absolutely the same every time (depending on the test generated by LibFuzzer), we run HAMER ten times for each code and then calculate the average repair time. We installed SAVER directly from their github~\footnote{https://github.com/kupl/SAVER\_public} (Infer version: v0.15.0-821a8db). Because SAVER relies on Infer's static analysis results, we must consider Infer's execution time when calculating SAVER's execution time. Table~\ref{evaluationresult} shows the final experimental results.



\begin{table}[t]
  \caption[Characteristics of synthesizing code]{Characteristics of synthesizing code. FN and FP denote that the code contains Infer's false-negative and false-positive alarms. EP denotes that the code contains the error with a long error path. ME denotes that the code contains multiple error heap objects. MR denotes that the code has multiple returns. CF denotes that the code has a complicated control flow.}
  \label{syncode}
  \centering
  \begin{tabular}{ccc}
   Syn & LoC  &  Feature \\
    \hline
    test1     & 12  &  CF \\
    test2     & 9   &  MR \\
    test3     & 23  &  EP, FN \\
    test4      & 11 &  FP, FN \\
    test5      & 15 &  EP, ME, FN \\
    test6      & 24 &  EP, ME, MR, FN \\
    test7      & 9   &  MR, CF, FN \\
    test8      & 26 &  EP, ME, FN \\
    test9     & 24  &  EP, ME, FN \\
    test10   & 15  &  ME, CF \\
    test11   & 15  &  EP, CF, FP \\
    \hline
  \end{tabular}
\end{table}



\begin{table}[h]
  \caption[Evaluation result]{Evaluation result of HAMER and SAVER. ML denotes the number of memory leaks. T, FP, and FN denote the number of true, false-positive, and false-negative alarms detected by Infer. Fuzzer denotes the number of memory leaks detected by LibFuzzer. $\checkmark$ and $\times$ report the correct and wrong patches generated by HAMER and SAVER. SA, Fuzz, and Total report the static analysis time, fuzzing time, and the total fix time. }
  \label{evaluationresult}
  \centering
  \makebox[1 \textwidth][c]{  
  \resizebox{1.1\textwidth}{!}{ 
  \begin{tabular}{cc|ccc|ccc|cccc}
                 &        &  \multicolumn{3}{|c|}{Infer}&  \multicolumn{3}{|c|}{SAVER}  & \multicolumn{4}{|c}{HAMER}  \\
   Syn & ML& T & FP/FN & sec & $\checkmark$ & $\times$ & sec & Fuzzer & $\checkmark$ & $\times$ & SA/Fuzz/Total  \\
    \hline
    test1         & 1  & 1  & 0/0     & 0.68  & 0  & 0  & 0.05      & 1   & 1    & 0  & 0.01/7.01/7.94 \\
    test2         & 2  & 2  & 0/0     & 0.13  & 2  & 0  & 0.07      & 2   & 2    & 0  & 0.01/7.27/8.42 \\
    test3         & 2  & 0  & 0/2     & 0.36  & -  & -  & -      & 2   & 2    & 0  & 0.04/7.71/9.14 \\
    test4         & 1  & 0  & 1/1     & 0.15  & 0  & 1  & 0.03      & 1   & 1    & 0  & 0.01/7.06/7.90 \\
    test5         & 2  & 0  & 0/2     & 0.14  & -  & -  & -      & 2   & 2    & 0  & 0.03/7.71/9.10 \\
    test6        & 3  & 0  & 0/3     & 0.28  & -  & -  & -      & 3   & 3    & 0  & 0.03/8.03/9.60 \\
    test7        & 2  & 1  & 0/1     & 0.14  & 0  & 1  & 0.05      & 2   & 2    & 0  & 0.01/7.43/8.61 \\
    test8        & 4  & 0  & 0/4     & 0.49  & -  & -  &  -      &  \begin{tabular}{c}3-4\\4\end{tabular}  & \begin{tabular}{c}0-3\\4 \end{tabular}   & \begin{tabular}{c}0-1\\0\end{tabular}  & \begin{tabular}{c}0.05/4.17/7.17\\0.05/9.94/13.17\end{tabular} \\
    test9         & 3  & 1  & 0/2     & 0.42  & 1  & 0  & 0.05      & 3   & 3    & 0  & 0.04/8.91/11.29 \\
    test10       & 2  & 2  & 0/0     & 0.42  & 1  & 1  &  0.07      &  2  & 2  & 0 & 0.02/7.67/9.04 \\
    test11       & 1  & 0  & 1/0     & 0.14  & 0  & 1  &  0.05      &  1  & 1  & 0 & 0.02/7.02/7.89 \\
    \hline
   Total/Ave & 23  & 7  & 2/16  & 0.32  & 4  & 4  &  0.05      &  22-23  & 19-23  & 0-1 & 0.03/7.49/9.10 \\
    \hline
  \end{tabular}
}}
\end{table}

\section{Experimental Results}

\subsection[Research Question 1]{Compared with state-of-the-art automated memory error repair tool SAVER, what is the overall effectiveness of HAMER?}

There are 23 memory leaks in the 11 test codes we synthesized. Infer found 7 memory leaks successfully, missed 16 memory leaks, and reported 2 false alarms. Because SAVER relies on infer's alarms to repair the code, it has no opportunity to fix the 16 unreported errors (false-negative). SAVER generated 4 correct patches and 2 wrong patches for the 7 alarms correctly reported by Infer, and it failed to identify Infer's false alarm and generated 2 wrong patches.

All 23 memory leaks were detected via LibFuzzer. For test8, LibFuzzer may not be able to detect all of the errors, also making it difficult to verify whether the patch generated by HAMER is correct or not. In \textbf{RQ2}, we will go over the details of test8. HAMER can generate all correct patches for other test codes and does not provide any erroneous patches. HAMER's average repair time is 9.10 seconds, although it is clear that the majority of that time is spent by LibFuzzer checking whether the patches are correct. We also set the fuzzing timeout to 5 seconds, which implies that any properly repaired test codes will take 5 seconds to confirm whether or not the patch is correct via LibFuzzer. We have already discussed the issues of indirect call and alias in Chapter~\ref{overview}, so we will not go over it again here.

Infer failed to detect two memory leaks in test5 (shown in Figure~\ref{test5}) because it cannot effectively deal with the alias. It made SAVER have no chance to fix errors (although this is easy for SAVER). Similar problems appear in test3,4,6,8,9 when memory is dynamically allocated at another function and then returned to the current function's pointer. LibFuzzer, on the other hand, tracks the memory situation via AddressSanitizer, which instruments all dynamic memory allocation, allowing it to quickly detect any memory leaks in codes with simple control flow. Because {\it o1} uses {\it o0}, if {\it o0} is freed before {\it o1}, use-after-free will occur. HAMER stores error heap objects via temporary variables, so we do not need to worry about the order of deallocation.

\begin{figure*}[h]
  \begin{subfigure}{0.53\textwidth}
    \lstinputlisting{test5.c}
    \caption{o0, o1 occur memory leak}
    \label{test5a}
  \end{subfigure}\hfill
  \begin{subfigure}{0.4\textwidth}
    \lstinputlisting[firstnumber=13]{test5res.c}
    \caption{HAMER-generated patch}
    \label{test5b}
  \end{subfigure}
  \caption{test5} 
  \label{test5}
\end{figure*}

In test10 (shown in Figure~\ref{test10}), although Infer detected two memory leaks, SAVER generated a correct patch and a wrong patch. SAVER can not fix multiple errors at the same time. If only fix {\it o0} without considering {\it o1}, the patch generated by SAVER at line10 is correct, but if the patch of {\it o1} at line11 is added, double free will occur. HAMER can fix multiple errors at the same time and check whether the generated patches will cause new errors, so it can fix test10 correctly

\begin{figure*}[t]
  \begin{subfigure}{0.45\textwidth}
    \lstinputlisting{test10.c}
    \caption{o0, o1 occur memory leak}
    \label{test10a}
  \end{subfigure}\hfill
  \begin{subfigure}{0.45\textwidth}
    \lstinputlisting[firstnumber=6]{test10saver.c}
    \caption{SAVER-generated patch}
    \label{test10b}
  \end{subfigure}
  \centering
  \begin{subfigure}{0.45\textwidth}
    \lstinputlisting[firstnumber=6]{test10res.c}
    \caption{HAMER-generated patch}
    \label{test10c}
  \end{subfigure}
  \caption{test10} 
  \label{test10}
\end{figure*}

In test11 (shown in Figure~\ref{test11}), {\it o0} allocated, deallocated, and leaked at 3 different functions. The error heap object was identified by Infer, but the leak location was incorrectly analyzed, and Infer reported the following alarm.

\begin{minipage}{\textwidth}
\vspace{0.2cm}
\textsl{\hspace{0.3cm}Object allocated at line 12 is unreachable at line 13.\\}
\end{minipage}
Since SAVER is unable to follow heap-related behavior across multiple functions, it generated the erroneous patch, as shown in Figure~\ref{test11b}. HAMER quickly detected the error heap object using LibFuzzer, collected the key tests, and successfully generated the conditional deallocation statement patch (Figure~\ref{test11c}).

\begin{figure*}[t]
  \begin{subfigure}{0.46\textwidth}
    \lstinputlisting{test11.c}
    \caption{o0 occurs memory leak}
    \label{test11a}
  \end{subfigure}\hfill
  \begin{subfigure}{0.45\textwidth}
    \lstinputlisting[firstnumber=11]{test11saver.c}
    \caption{SAVER-generated patch}
    \label{test11b}
  \end{subfigure}
  \centering
  \begin{subfigure}{0.45\textwidth}
    \lstinputlisting[firstnumber=11]{test11res.c}
    \caption{HAMER-generated patch}
    \label{test11c}
  \end{subfigure}
  \caption{test11} 
  \label{test11}
\end{figure*}

\vspace{0.4cm}
\hspace{-0.7cm}\fbox{\begin{minipage}{\textwidth}
HAMER has a higher repairability than SAVER. HAMER has more opportunities to repair more memory leaks, as well as better handling of issues like multiple errors, indirect calls, and alias, and is less likely to generate erroneous patches.
\end{minipage}}


\subsection[Research Question 2]{Can HAMER address the three major issues we mentioned in Chapter~\ref{approach}? }

\begin{figure*}[t]
  \begin{subfigure}{0.5\textwidth}
    \lstinputlisting{test8.c}
    \caption{o0, o1, o2, o3 occur memory leak}
    \label{test8a}
  \end{subfigure}\hfill
  \begin{subfigure}{0.4\textwidth}
    \lstinputlisting[firstnumber=18]{test8a.c}
    \caption{HAMER-generated correct patch}
    \label{test8b}
  \end{subfigure}
  \begin{subfigure}{0.5\textwidth}
    \lstinputlisting[firstnumber=18]{test8b.c}
    \caption{LibFuzzer only detect 3 errors at first, so HAMER failed to generate patch}
    \label{test8c}
  \end{subfigure}\hfill
  \begin{subfigure}{0.4\textwidth}
    \lstinputlisting[firstnumber=18]{test8c.c}
    \caption{LibFuzzer failed to verify the wrong patch, make HAMER generate wrong patch and failed to generate the patch of o3}
    \label{test8d}
  \end{subfigure}
  \caption{test8} 
  \label{test8}
\end{figure*}


To synthesize correct conditional, HAMER continuously updates the test suite until the correct patch is generated or timeout. For {\it o1} in test10, sometimes LibFuzzer can not directly provide a significant test (e.g.,$(a: 5, error: True)$),  causing HAMER to generate the wrong conditional \verb|a>=4|. However, HAMER checked the patch via LibFuzzer and found that the memory leak of {\it o1} still existed when \verb|a=5|, so HAMER added this test to the test suite and generated the correct patch at last.

HAMER tries to insert the patch to each candidate fix location and verifies the patch via LibFuzzer. Test2, 6, 7 all have multiple returns, and HAMER successfully fixed them all, so HAMER can deal with the case of multiple returns in a function.

HAMER will repair each error one by one via HAMER's repair algorithm shown in Chapter~\ref{approach}. HAMER is able to reach 100\% repairability for the function which has two error heap objects (e.g., tests 5, 6, 9, 10). Due to the feature of LibFuzzer, LibFuzzer stops and outputs results when it detects the error on the current explored path, so if multiple error heap objects exist on multiple different paths, LibFuzzer will be unable to detect all the errors at the same time, causing HAMER failed to generate patches. However, we can solve this problem by improving our repair algorithm, which we will discuss in the Future Work in Chapter~\ref{conclusion}.

Figure~\ref{test8} shows the correct and incorrect patches generated by HAMER for test8. Test8 has four error heap objects ({\it o0, o1, o2, o3}). In most cases, LibFuzzer can detect all of the errors and give the necessary tests, enabling HAMER to successfully fix test8 as shown in Figure~\ref{test8b}. However, due to a large number of errors, LibFuzzer may not be able to detect all of them. For example, test8 has two paths(\verb|a<5|, \verb|a>=5|), as shown in Figure~\ref{test8c}, and executing either path will trigger the memory leaks of {\it o0, o1, o3}. Although we initially set LibFuzzer to run 10 times in order to detect all errors, there were sometimes that the produced tests were all \verb|>=5|, so that the path of \verb|a<5| has never been entered and the memory leak of {\it o2} has never been triggered. Although HAMER could generate the correct patch for {\it o0, o1, o3}, when checked by LibFuzzer, each patch will cause the memory leak of {\it o2} and HAMER will determine that the current patch is not correct since it will cause a new error.

The instance of HAMER generating an error patch is also shown in Figure~\ref{test8d}. In beginning, HAMER generated the right patches of {\it o0} and {\it o1}. HAMER synthesized conditional \verb|a>=2| with the current test suite when trying to fix {\it o2}. Then, using LibFuzzer, we can determine that the current patch was erroneous, and for example, we can collect the test of $(a: 4, error: True)$, and synthesize conditional \verb|a>=4|. However, because {\it o3} has not been repaired and whatever was input memory leak for {\it o3} will be triggered, LibFuzzer failed to input the critical test \verb|a=5| to trigger {\it o2}, causing HAMER to incorrectly judge this patch as the correct one and keep it, even LibFuzzer executed 10 times. When fixing {\it o3}, since {\it o3} was fixed correctly, LibFuzzer explored all paths and triggered the memory leak of {\it o2}, causing HAMER to incorrectly judge the patch of {\it o3} as the wrong patch. Finally, HAMER generated an incorrect patch and deleted a correct patch.

\vspace{0.4cm}
\hspace{-0.7cm}\fbox{\begin{minipage}{\textwidth}
HAMER can handle multiple returns, multiple errors, and collect critical tests, although performance will be affected when the number of errors increases.
\end{minipage}}


\subsection[Research Question 3]{How efficient is HAMER in using lightweight static analysis?}
The repair times for HAMER and SAVER are shown in Table~\ref{evaluationresult}. HAMER is a memory error repair tool based on hybrid analysis, which collects information for repair using lightweight static analysis. SAVER is a static memory error repair tool that uses static analysis from detection to repair. SAVER's repair time is quite short, but it can not guarantee the correctness of the patches it generated, and its repairability is not as good as HAMER's. HAMER's repair time is longer, but it is obvious that most of the time is spent on fuzzing, and due to our settings, HAMER spends 5 seconds at the end of the repair checking the correctness of the patches using LibFuzzer. The lightweight static analysis utilized by HAMER can collect the essential information to assist HAMER in generating the correct patches in a very short time. The HAMER repair algorithm does not require time to collect a large amount of heap-related behavior through static analysis, and experimental results also show that HAMER has not failed to repair errors due to our lightweight static analysis missing essential information.

\vspace{0.4cm}
\hspace{-0.7cm}\fbox{\begin{minipage}{\textwidth}
Our lightweight static analysis can collect enough information in a short time to assist HAMER to generate the correct patches.
\end{minipage}}

%---------------------------------------------------------------------------------------
%      Related work
%----------------------------------------------------------------------------------------
\chapter{Related Work}
Existing repair techniques can be categorized as general-purpose or special-purpose, depending on whether they are intended to fix all types of errors or only specific types of errors. HAMER is a special-purpose technique that focuses on fixing temporal memory errors such as memory leaks. Other specialized techniques focus on buffer overflows~\cite{buffer}, null dereferences~\cite{Getafix,npe}, etc.. We compared the features of several related techniques shown in Table~\ref{relate}.

There are many studies focused on fixing memory errors~\cite{melt,leakpoint,leakfix,survey,ownership,transfor,typebase,fractional,footpatch,leakchaser,defleak,SAVER}. Among this, the most directly related to our research is MemFix~\cite{Memfix} and SAVER~\cite{SAVER}. MemFix starts by removing all deallocation statements from the program, then uses static analysis to trace and collect all heap objects and their candidate fix locations, and finally finds a set of patches that can free all dynamically allocated memory without introducing memory errors. However, MemFix cannot generate conditional deallocation statements and has limited scalability and repairability. SAVER is the state-of-the-art memory error repair technique, with high scalability and repairability. SAVER first uses Infer to detect the memory error and then collects the heap-related behavior of the program through static analysis and constructs the object flow graph. SAVER's repair algorithm converts the memory error repair problem into the relabeling problem of the object flow graph and can avoid generating wrong patches by considering the relationship between heap objects. However, due to the limitations of static analysis, SAVER cannot understand the dynamic information of the program, which makes it fail to fix some errors or generate erroneous patches. HAMER uses fuzzer to detect programs, allowing HAMER has more opportunities to fix errors (static analyzer's false-negative) and do not spend time on wrong alarms (static analyzer's false-positive). HAMER also uses fuzzer to check generated patches, preventing HAMER from generating wrong patches. HAMER's extensive repair strategy allows it to handle various kinds of memory errors. DEF\_LEAK~\cite{defleak} is a dynamic approach to detecting, eliminating, and fixing memory leaks. DEF\_LEAK first instruments the program for collecting memory information and then exposes memory leaks through dynamic symbolic execution. DEF\_LEAK can generate the deallocation statement patch to eliminate the leaks at run time. However, DEF\_LEAK's repair strategy is very simple (just add deallocation statement at suitable location) and can not fix complicated memory errors, so it does not have high repairability. HAMER uses a conditional deallocation statement to fix the error, so it can fix a leak in a typical path. HAMER can also deallocate a heap object at multiple leak locations.

General-purpose program repair techniques can be classified as semantics-based techniques~\cite{jfix,semfix,directfix,Angelix,Extractfix,CPR,acs} and search-based techniques~\cite{par,s3, spr, prophet,cp}. Search-based techniques search for the correct patch in a certain search space, so although it has high scalability, the quality of the generated patches is often poor and the overhead is high. Getafix~\cite{Getafix} fixes errors by learning from developers' past fixing history. Getafix has high scalability and repairability for fixing errors with simple repair patterns such as null dereference. Although fixing memory errors often only requires inserting a deallocation statement, the fix location is usually too far away from the error source, which Getafix can not handle, and Getafix is a static technique, so it cannot guarantee the correctness of the generated patch. Semantics-based techniques collect path constraints through symbolic execution and then synthesize patches through CBPS. Angelix~\cite{Angelix} has high scalability and can fix multi-location bugs, but like other semantics-based techniques, Angelix is prone to generating overfitting patches, therefore its repairability entirely depends on the quality of the test suite. HAMER can collect the tests triggered errors generated by the fuzzer, which are essential to synthesize the correct patches. CPR~\cite{CPR} collects essential tests for patch synthesis by exploring input and patch space through concolic execution. ExtractFix~\cite{Extractfix} improves the performance of CPBS by collecting the sanitizer's constraint and the tests triggered sanitizer. ExtractFix also uses the crash location as the starting point and performs backward control and data-dependency analysis along with crashing path to collect candidate fix locations, so it has the ability to fix the error kinds which have the different crash and fix locations. The main reason these techniques do not perform well in fixing memory errors is that they cannot identify the correct fix location and it is difficult for them to guarantee the correctness of the patches they generated. HAMER collects essential tests via fuzzer, so it does not need the test suite at the beginning. HAMER collects the candidate fix location via lightweight static analysis and uses a fuzzer to find the correct fix location and verify the generated patches. HAMER is a memory error repair technique that can be fully automated among the processes of detection, repair, and verification. 

\begin{table}[t]
  \caption{Related works}
  \label{relate}
  \centering
  \begin{tabular}{|c|c|cccc|}
    \hline
   Target & Technique  &  Fix location & Test suite& Patch & Verification \\
    \hline
    \multirow{4}{*}{\begin{tabular}{c}General\\purpose\end{tabular}} & Angelix & statistical    & necessary  &  static & manual \\
                 & CPR     & user input   & unnecessary & dynamic & manual\\
                 & ExtractFix  & static &  crash input &  static & manual \\
                 & Getafix  & static &  training data &  static & manual \\
    \hline
    \multirow{3}{*}{\begin{tabular}{c}Memory\\error\end{tabular}} & SAVER    & static & unnecessary & static & static \\
                 & DEF\_LEAK  & dynamic &  unnecessary & static & manual \\
                 & HAMER      & hybrid &  unnecessary & hybrid & dynamic \\
    \hline
  \end{tabular}
\end{table}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%---------------------------------------------------------------------------------------
%      Limitation
%----------------------------------------------------------------------------------------
\chapter{Conclusion}
\label{conclusion}
\section{Conclusion}
Fixing memory errors is difficult because new and more dangerous errors are easily introduced. In this research, we presented a new automated memory error repair technique based on hybrid analysis. HAMER dynamically detects memory errors and verifies generated patches via fuzzer and collects essential information for repair via lightweight static analysis. Experiments show that HAMER can fix the complicated memory errors effectively, which the existing static memory error repair technique can not repair. In the future, HAMER is expected to get better scalability and repairability.
\section{Limitations}
Since we use CBPS to synthesize the conditional of the patch and CBPS can only synthesize the numeric conditionals, HAMER can not synthesize the conditional that includes other types of elements, such as strings. HAMER is also unable to repair memory errors for parallelism. Finally, HAMER's current repair algorithm cannot handle the loop. If a variable is in a loop, for example, it will yield multiple values for a fuzzer input, making it impossible for HAMER to build an expected test suite. Similarly, if the program does dynamic memory allocation in a loop, HAMER can only fix the memory leaks that occur in each loop one by one, but the correct patch may just require deallocation in the loop.
\section{Future Work}
HAMER is an automated memory error repair tool. Although HAMER can only fix memory leaks at the present, we can simply extend our repair algorithm to fix use-after-free and double-free errors. We can fix use-after-free by first removing the free function and then treating it as a memory leak. Similarly, deleting the redundant free function for double free may either fix the error or introduce a memory leak, which we can also fix using the current approach.

We can also improve our repair algorithm to prevent patches from failing to generate patches or generating wrong patches due to fuzzer faults, such as test8. To avoid this issue, HAMER's current strategy is to run fuzzer multiple times to decrease the probability of an error being missed. We have two ways of improving HAMER's performance.
\begin{itemize}
\item If a new dynamic memory leak is detected during the repair process, we compare it to the previously detected errors and add it to our repair list if it is a new error.
\item If we trigger a previously repaired error when repairing the current error, we add that error back to the repair list.
\end{itemize}

At this time, our implementation of simp-CBPS can only synthesize the conditional of a few templates, thus we need to expand the types of conditional by adding more conditional template specifications. We also need to increase HAMER's scalability and figure out how to deal with the loop.








%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\bibliographystyle{plain}
\bibliography{mybib}
%\begin{thebibliography}{99}
%  \bibitem{tokodai-xyz2015} Taro Tokodai. How to write a good thesis. \textit{Journal of XYZ}, 3(4):15--34, 2015.
%\end{thebibliography}

\end{document}
